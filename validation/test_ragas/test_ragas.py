"""
Script de ejemplo para usar RAGAS (Retrieval-Augmented Generation Assessment)
Este script demuestra c√≥mo evaluar sistemas RAG usando diferentes m√©tricas de RAGAS.

RAGAS es un framework para evaluar aplicaciones de Retrieval-Augmented Generation (RAG).
Proporciona m√©tricas espec√≠ficas para evaluar tanto la calidad de la recuperaci√≥n de informaci√≥n
como la calidad de la generaci√≥n de respuestas.

=== M√âTRICAS DE RECUPERACI√ìN (Retrieval) ===
Estas m√©tricas eval√∫an qu√© tan bien el sistema recupera informaci√≥n relevante:

1. Context Precision (context_precision):
   - Mide qu√© tan precisos son los contextos recuperados
   - Eval√∫a si los fragmentos recuperados son relevantes para la pregunta
   - Valores m√°s altos indican mejor precisi√≥n en la recuperaci√≥n

2. Context Recall (context_recall):
   - Mide qu√© tan completa es la recuperaci√≥n de informaci√≥n relevante
   - Eval√∫a si se recuper√≥ toda la informaci√≥n necesaria para responder
   - Compara el ground_truth con los contexts para ver si toda la info est√° presente
   - IMPORTANTE: Si sale 0, significa que el ground_truth no coincide con los contexts
   - Valores m√°s altos indican mejor cobertura de informaci√≥n relevante

3. Context Relevance (ContextRelevance):
   - Eval√∫a la relevancia general de los contextos recuperados
   - Mide qu√© tan relacionados est√°n los contextos con la pregunta
   - Combina aspectos de precisi√≥n y utilidad del contexto

=== M√âTRICAS DE GENERACI√ìN (Generation) ===
Estas m√©tricas eval√∫an la calidad de las respuestas generadas:

4. Answer Relevancy (answer_relevancy):
   - Mide qu√© tan relevante es la respuesta generada para la pregunta
   - Eval√∫a si la respuesta aborda directamente lo que se pregunta
   - No considera la correcci√≥n factual, solo la relevancia

5. Answer Similarity (answer_similarity):
   - Compara la similitud sem√°ntica entre la respuesta generada y la respuesta ideal
   - Usa embeddings para medir similitud conceptual
   - √ötil cuando hay m√∫ltiples formas correctas de responder

6. Answer Correctness (answer_correctness):
   - Eval√∫a la correcci√≥n factual de la respuesta generada
   - Combina aspectos sem√°nticos y factuales
   - Considera tanto la exactitud como la completitud de la informaci√≥n

7. Faithfulness (faithfulness):
   - Mide qu√© tan fiel es la respuesta al contexto proporcionado
   - Eval√∫a si la respuesta se basa √∫nicamente en la informaci√≥n recuperada
   - Detecta alucinaciones o informaci√≥n no respaldada por el contexto

=== INTERPRETACI√ìN DE RESULTADOS ===
- Valores cercanos a 1.0: Excelente rendimiento
- Valores entre 0.7-0.9: Buen rendimiento
- Valores entre 0.5-0.7: Rendimiento moderado que requiere mejoras
- Valores menores a 0.5: Rendimiento pobre que requiere revisi√≥n significativa

=== USO DEL SCRIPT ===
1. Configura tu OPENAI_API_KEY en el archivo .env
2. Ejecuta: python ragas_personalizado.py
3. Revisa los resultados en pantalla y en el archivo resultados_ragas.csv
"""

import os
import sys
from pathlib import Path

import pandas as pd
from datasets import Dataset
from dotenv import load_dotenv

# Importaciones de RAGAS
from ragas import evaluate
from ragas.metrics import (
    ContextRelevance,
    answer_correctness,
    answer_relevancy,
    answer_similarity,
    context_precision,
    context_recall,
    faithfulness,
)


def cargar_variables_entorno():
    """Cargar variables de entorno desde el archivo .env en la ra√≠z del proyecto"""
    # Buscar el archivo .env en la ra√≠z del proyecto
    proyecto_raiz = Path(__file__).parent.parent.parent
    env_path = proyecto_raiz / ".env"

    if env_path.exists():
        load_dotenv(env_path)
        print(f"‚úÖ Variables de entorno cargadas desde: {env_path}")
    else:
        print(f"‚ö†Ô∏è  No se encontr√≥ archivo .env en: {env_path}")
        print("Por favor, crea un archivo .env con tu OPENAI_API_KEY")
        return False

    # Verificar que la API key est√© disponible
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key or api_key == "tu_api_key_aqui":
        print("‚ùå OPENAI_API_KEY no est√° configurada correctamente en el archivo .env")
        return False

    print("‚úÖ OPENAI_API_KEY cargada correctamente")
    return True


def crear_datos_ejemplo():
    """Crear datos de ejemplo para evaluar con RAGAS"""
    # IMPORTANTE para context_recall:
    # - ground_truth = respuesta IDEAL que se puede construir con los contexts
    # - NO debe ser copia exacta de un context
    # - S√ç puede combinar informaci√≥n de m√∫ltiples contexts
    # - context_recall mide si los contexts contienen toda la info del ground_truth

    datos_ejemplo = {
        "question": [
            "¬øCu√°l es la capital de Francia y d√≥nde se encuentra?",
            "¬øC√≥mo funciona la fotos√≠ntesis y qu√© produce?",
            "¬øQu√© es el machine learning y para qu√© sirve?",
        ],
        "answer": [
            "La capital de Francia es Par√≠s, una ciudad ubicada en el norte del pa√≠s y es la m√°s poblada.",
            "La fotos√≠ntesis es el proceso por el cual las plantas usan luz solar, di√≥xido de carbono y agua para producir glucosa y ox√≠geno.",
            "Machine learning es un m√©todo de an√°lisis de datos que automatiza la construcci√≥n de modelos anal√≠ticos para permitir a las m√°quinas aprender patrones.",
        ],
        "contexts": [
            [
                "Par√≠s es la capital y ciudad m√°s poblada de Francia. Se encuentra en el norte del pa√≠s.",
                "Francia es un pa√≠s europeo con una rica historia cultural.",
                "Par√≠s tiene una poblaci√≥n de m√°s de 2 millones de habitantes en la ciudad.",
            ],
            [
                "La fotos√≠ntesis es el proceso biol√≥gico donde las plantas usan luz solar, di√≥xido de carbono y agua para producir glucosa y ox√≠geno.",
                "Este proceso ocurre principalmente en las hojas de las plantas.",
                "La clorofila es el pigmento verde que captura la luz solar para la fotos√≠ntesis.",
            ],
            [
                "El machine learning es un m√©todo de an√°lisis de datos que automatiza la construcci√≥n de modelos anal√≠ticos.",
                "Permite a las m√°quinas aprender patrones de los datos sin ser programadas expl√≠citamente.",
                "Se utiliza en aplicaciones como reconocimiento de im√°genes y procesamiento de lenguaje natural.",
            ],
        ],
        "ground_truth": [
            "La capital de Francia es Par√≠s, ubicada en el norte del pa√≠s y es su ciudad m√°s poblada.",
            "La fotos√≠ntesis es el proceso donde las plantas usan luz solar, CO2 y agua para crear glucosa y ox√≠geno, principalmente en las hojas usando clorofila.",
            "El machine learning automatiza la construcci√≥n de modelos anal√≠ticos para que las m√°quinas aprendan patrones de datos, usado en reconocimiento de im√°genes y NLP.",
        ],
    }

    return Dataset.from_dict(datos_ejemplo)


def ejecutar_evaluacion_ragas():
    """Ejecutar evaluaci√≥n usando m√©tricas de RAGAS"""

    print("üöÄ Iniciando evaluaci√≥n con RAGAS...")

    # Crear dataset de ejemplo
    dataset = crear_datos_ejemplo()
    print(f"üìä Dataset creado con {len(dataset)} ejemplos")

    # Definir m√©tricas a evaluar
    metricas = [
        answer_relevancy,
        answer_similarity,
        answer_correctness,
        faithfulness,
        context_precision,
        context_recall,
        ContextRelevance(),
    ]

    print("üìã M√©tricas a evaluar:")
    for metrica in metricas:
        print(f"  - {metrica.name}")

    try:
        # Ejecutar evaluaci√≥n
        print("\n‚è≥ Ejecutando evaluaci√≥n (esto puede tomar unos minutos)...")
        resultado = evaluate(
            dataset=dataset,
            metrics=metricas,
        )

        print("\n‚úÖ Evaluaci√≥n completada!")
        return resultado

    except Exception as e:
        print(f"‚ùå Error durante la evaluaci√≥n: {str(e)}")
        return None


def mostrar_resultados(resultado):
    """Mostrar los resultados de la evaluaci√≥n"""

    if resultado is None:
        print("‚ùå No hay resultados para mostrar")
        return

    print("\n" + "=" * 60)
    print("üìä RESULTADOS DE LA EVALUACI√ìN RAGAS")
    print("=" * 60)

    # Convertir a DataFrame para mejor visualizaci√≥n
    df_resultados = resultado.to_pandas()

    print(f"\nüìã Columnas disponibles en los resultados: {list(df_resultados.columns)}")

    # Mostrar estad√≠sticas generales
    print("\nüìà Puntuaciones promedio por m√©trica:")
    print("-" * 40)

    metricas_numericas = df_resultados.select_dtypes(include=["float64", "int64"]).columns

    for metrica in metricas_numericas:
        if metrica in df_resultados.columns:
            promedio = df_resultados[metrica].mean()
            print(f"{metrica:25s}: {promedio:.3f}")

    print("\nüìã Resultados detallados por fila:")
    print("-" * 40)

    for i, row in df_resultados.iterrows():
        print(f"\nFila {i+1}:")
        for metrica in metricas_numericas:
            if metrica in row:
                print(f"  {metrica:20s}: {row[metrica]:.3f}")

    # Mostrar todas las columnas y valores
    print("\nüìã DataFrame completo:")
    print("-" * 40)
    print(df_resultados.to_string())

    # Guardar resultados en CSV
    archivo_resultados = "resultados_ragas.csv"
    df_resultados.to_csv(archivo_resultados, index=False, encoding="utf-8")
    print(f"\nüíæ Resultados guardados en: {archivo_resultados}")


def main():
    """Funci√≥n principal"""
    print("üîß RAGAS - Evaluaci√≥n de Sistemas RAG")
    print("=" * 50)

    # Cargar variables de entorno
    if not cargar_variables_entorno():
        print("\n‚ùå No se pueden cargar las variables de entorno necesarias")
        print("Por favor:")
        print("1. Crea un archivo .env en la ra√≠z del proyecto")
        print("2. Agrega tu OPENAI_API_KEY=tu_clave_real")
        sys.exit(1)

    # Ejecutar evaluaci√≥n
    resultado = ejecutar_evaluacion_ragas()

    # Mostrar resultados
    mostrar_resultados(resultado)

    print("\n‚úÖ Evaluaci√≥n completada exitosamente!")


if __name__ == "__main__":
    main()
