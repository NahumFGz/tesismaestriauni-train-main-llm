{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Optional, List, Tuple\n",
    "from uuid import uuid4\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import trim_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "class ChatState(TypedDict):\n",
    "    raw_messages: Annotated[list, add_messages]\n",
    "    messages: Annotated[list, add_messages]\n",
    "    topic_decision: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rewriter = init_chat_model(\"anthropic:claude-sonnet-4-20250514\", temperature=0.0)\n",
    "model_rewriter_fallback = init_chat_model(\"openai:gpt-4o\", temperature=0.0)\n",
    "llm_rewriter = model_rewriter.with_fallbacks([model_rewriter_fallback])\n",
    "\n",
    "model_classifier = init_chat_model(\"anthropic:claude-3-haiku-20240307\", temperature=0.0)\n",
    "model_classifier_fallback = init_chat_model(\"openai:gpt-4o\", temperature=0.0)\n",
    "llm_classifier = model_classifier.with_fallbacks([model_classifier_fallback])\n",
    "\n",
    "model_main = init_chat_model(\"anthropic:claude-sonnet-4-20250514\", temperature=0.5, streaming=True)\n",
    "model_main_fallback = init_chat_model(\"openai:gpt-4o\", temperature=0.5, streaming=True)\n",
    "llm_main = model_main.with_fallbacks([model_main_fallback])\n",
    "\n",
    "model_fallback = init_chat_model(\"anthropic:claude-3-haiku-20240307\", temperature=0.5, streaming=True)\n",
    "model_fallback_fallback = init_chat_model(\"openai:gpt-4o\", temperature=0.5, streaming=True)\n",
    "llm_fallback = model_fallback.with_fallbacks([model_fallback_fallback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_for_classification(messages, strategy=\"last\", max_chars=1000):\n",
    "    \"\"\"\n",
    "    Trim rápido usando caracteres como proxy de tokens\n",
    "    Estimación: ~4 caracteres por token en español\n",
    "    \"\"\"\n",
    "    if len(messages) <= 5:\n",
    "        return messages\n",
    "    \n",
    "    # Función inline para contar caracteres\n",
    "    def count_chars(msgs):\n",
    "        return sum(len(msg.content) for msg in msgs)\n",
    "    \n",
    "    trimmer = trim_messages(\n",
    "        max_tokens=max_chars,\n",
    "        strategy=strategy, \n",
    "        token_counter=count_chars,\n",
    "        include_system=False,\n",
    "        allow_partial=False,\n",
    "        start_on=\"human\",\n",
    "    )\n",
    "    \n",
    "    return trimmer.invoke(messages)\n",
    "\n",
    "\n",
    "\n",
    "def format_history_context(messages: List, max_chars: int = 200, exclude_last: bool = False, last_n: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Formatea el historial en pares Q: A: excluyendo la última pregunta.\n",
    "    - Agrupa en pares (HumanMessage, AIMessage).\n",
    "    - Muestra pregunta completa con prefijo Q:.\n",
    "    - Trunca cada respuesta a max_chars con prefijo A: y añade '…'.\n",
    "    - Cada par en una línea separada.\n",
    "    - Solo incluye los últimos last_n pares.\n",
    "    \"\"\"\n",
    "    pairs: List[Tuple[HumanMessage, Optional[AIMessage]]] = []\n",
    "    pending_human = None\n",
    "    \n",
    "    # Si exclude_last=True, no procesamos el último mensaje\n",
    "    messages_to_process = messages[:-1] if exclude_last and messages else messages\n",
    "\n",
    "    for msg in messages_to_process:\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            # Si ya había un HumanMessage pendiente, lo guardamos sin respuesta\n",
    "            if pending_human is not None:\n",
    "                pairs.append((pending_human, None))\n",
    "            pending_human = msg\n",
    "        elif isinstance(msg, AIMessage) and pending_human is not None:\n",
    "            pairs.append((pending_human, msg))\n",
    "            pending_human = None\n",
    "    \n",
    "    # Guardar el último HumanMessage si quedó pendiente\n",
    "    if pending_human is not None:\n",
    "        pairs.append((pending_human, None))\n",
    "\n",
    "    # Tomar solo los últimos last_n pares\n",
    "    recent_pairs = pairs[-last_n:] if last_n > 0 else pairs\n",
    "\n",
    "    lines = []\n",
    "    for human, ai in recent_pairs:\n",
    "        # Pregunta completa con prefijo Q:\n",
    "        q = human.content.strip()\n",
    "        lines.append(f\"Q: {q}\")\n",
    "\n",
    "        # Respuesta truncada con prefijo A: (si existe)\n",
    "        if ai is not None:\n",
    "            a = ai.content.strip()\n",
    "            if len(a) > max_chars:\n",
    "                # Buscar el último espacio antes del límite para no cortar palabras\n",
    "                cut_point = a.rfind(' ', 0, max_chars)\n",
    "                if cut_point == -1:\n",
    "                    cut_point = max_chars\n",
    "                snippet = a[:cut_point].rstrip() + \"…\"\n",
    "            else:\n",
    "                snippet = a\n",
    "            lines.append(f\"A: {snippet}\")\n",
    "        else:\n",
    "            # Si no hay respuesta, indicamos que no hay respuesta\n",
    "            lines.append(\"A: [Pendiente de responder...]\")\n",
    "        \n",
    "        # Línea vacía entre pares para separar\n",
    "        lines.append(\"\")\n",
    "\n",
    "    return \"\\n\".join(lines).strip() + \"\\n\"\n",
    "\n",
    "def get_last_question(messages: List) -> str:\n",
    "    \"\"\"\n",
    "    Obtiene la última pregunta del usuario de la lista de mensajes.\n",
    "    \"\"\"\n",
    "    if not messages:\n",
    "        return \"\"\n",
    "    \n",
    "    # Buscar el último HumanMessage\n",
    "    for msg in reversed(messages):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            return msg.content.strip()\n",
    "    \n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewriter_msg = SystemMessage(\n",
    "    content=(\n",
    "        \"Eres un asistente especializado en reescribir preguntas para alinearlas con el contexto de transparencia gubernamental del Estado peruano. \"\n",
    "        \"Tu objetivo es transformar las preguntas del usuario en consultas más claras, formales y orientadas a la fiscalización y el acceso a información pública.\"\n",
    "\n",
    "        \"INSTRUCCIONES IMPORTANTES:\"\n",
    "        \"1. Solo reescribe preguntas relacionadas con los temas específicos listados abajo.\"\n",
    "        \"2. Si la pregunta NO está relacionada con estos temas, devuélvela EXACTAMENTE sin cambios.\"\n",
    "        \"3. Tu respuesta debe ser ÚNICAMENTE una pregunta reformulada, NUNCA una respuesta o explicación.\"\n",
    "        \"4. NUNCA generes respuestas largas o explicaciones, solo reformula la pregunta.\"\n",
    "\n",
    "        \"TEMAS PARA REESCRIBIR:\"\n",
    "        \"- Contrataciones públicas (montos, órdenes de servicio, contratos, proveedores)\"\n",
    "        \"- Empresas que han contratado con el Estado peruano\"\n",
    "        \"- Asistencia y votaciones de congresistas\"\n",
    "        \"- Información relacionada a congresistas (identidad, región, actividad legislativa)\"\n",
    "        \n",
    "        \"Ejemplos:\"\n",
    "        \"Entrada: quien es alejando muñante\"\n",
    "        \"Salida: Busca en la web información sobre el congresista ALEJANDRO MUÑANTE.\"\n",
    "\n",
    "        \"Entrada: quien es Sucel Paredes\"\n",
    "        \"Salida: Busca en la web información sobre la congresista SUCEL PAREDES.\"\n",
    "\n",
    "        \"Entrada: quienes son los congresistas de la region de huancayo\"\n",
    "        \"Salida: Busca en la web información sobre los congresistas de la región de HUANCAYO.\"\n",
    "        \n",
    "        \"Entrada: dame las asistencias del 2022 octubre\"\n",
    "        \"Salida: ¿Cuáles fueron las asistencias de los congresistas en octubre de 2022?\"\n",
    "\n",
    "        \"Entrada: puedes darme las asistencias del 10 de diciembre del 2022\"\n",
    "        \"Salida: ¿Cuáles fueron las asistencias de los congresistas el 2022-12-10?\"\n",
    "\n",
    "        \"Entrada: puedes decirme las votaciones del congreso del 10 de diciembre del 2022\"\n",
    "        \"Salida: ¿Cuáles fueron las votaciones de los congresistas el 2022-12-10?\"\n",
    "\n",
    "        \"Entrada: que asuntos se trataron en el congreso del 10 de diciembre del 2022\"\n",
    "        \"Salida: ¿Cuáles fueron los asuntos tratados en las votaciones del 2022-12-10?\"\n",
    "\n",
    "        \"Entrada: cuánto ha contratado constructora alfa\"\n",
    "        \"Salida: ¿Cuánto ha contratado la empresa 'CONSTRUCTORA ALFA' con el Estado peruano según transparencia pública?\"\n",
    "\n",
    "        \"Entrada: detalles de los contratos de constructora alfa\"\n",
    "        \"Salida: ¿Cuáles son los detalles de los contratos de la empresa 'CONSTRUCTORA ALFA'?\"\n",
    "\n",
    "        \"Entrada: detalles de las ordenes de servicio de constructora alfa\"\n",
    "        \"Salida: ¿Cuáles son los detalles de las órdenes de servicio de la empresa 'CONSTRUCTORA ALFA'?\"\n",
    "\n",
    "        \"Entrada: que mas puedes hacer\"\n",
    "        \"Salida: que mas puedes hacer\"\n",
    "\n",
    "        \"Entrada: Que más me puedes decir?\"\n",
    "        \"Salida: Que más me puedes decir?\"\n",
    "\n",
    "        \"Entrada: Me gustan los duraznos\"\n",
    "        \"Salida: Me gustan los duraznos\"\n",
    "\n",
    "        \"Entrada: Quien ganó la champions league\"\n",
    "        \"Salida: Quien ganó la champions league\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_node(state: ChatState) -> ChatState:\n",
    "    \"\"\"Reescribe la última pregunta del usuario con llm_rewriter.\"\"\"\n",
    "    \n",
    "    last_user_msg: HumanMessage = state[\"raw_messages\"][-1]   # asumimos último mensaje = usuario\n",
    "    rewritten = llm_rewriter.invoke([rewriter_msg, last_user_msg])\n",
    "    \n",
    "    # Validación: si la respuesta es muy larga (más de 300 chars), usa el mensaje original\n",
    "    rewritten_content = rewritten.content.strip()\n",
    "    if len(rewritten_content) > 3*len(last_user_msg.content):\n",
    "        print(f\"WARNING: Rewriter generó respuesta muy larga ({len(rewritten_content)} chars), usando mensaje original\")\n",
    "        rewritten_content = last_user_msg.content\n",
    "\n",
    "    # Añadimos la versión reescrita como HumanMessage (para mantener formato)\n",
    "    return {\n",
    "        \"raw_messages\": state[\"raw_messages\"],\n",
    "        \"messages\": state[\"messages\"] + [HumanMessage(content=rewritten_content)],\n",
    "        \"topic_decision\": state.get(\"topic_decision\", \"\")\n",
    "    }\n",
    "\n",
    "def classifier_node(state: ChatState) -> ChatState:\n",
    "    \"\"\"Clasifica si la conversación está relacionada con transparencia gubernamental.\"\"\"\n",
    "    \n",
    "    # Usamos `messages` (el output del rewriter) para el contexto\n",
    "    msgs_for_context = state[\"messages\"]\n",
    "    \n",
    "    # Obtener contexto histórico (excluyendo la última pregunta)\n",
    "    history_context = format_history_context(msgs_for_context, max_chars=200, exclude_last=True, last_n=4)\n",
    "    \n",
    "    # Obtener la última pregunta\n",
    "    last_question = get_last_question(msgs_for_context)\n",
    "    \n",
    "    print(\"CONTEXTO HISTÓRICO:\")\n",
    "    print(history_context)\n",
    "    print(\"ÚLTIMA PREGUNTA:\")\n",
    "    print(last_question)\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Eres un verificador que decide si la última pregunta del usuario puede ser respondida en el contexto de transparencia gubernamental del Estado peruano.\n",
    "\n",
    "    TEMAS RELEVANTES:\n",
    "    - Contrataciones públicas (montos, órdenes de servicio, contratos, proveedores)\n",
    "    - Empresas que han contratado con el Estado peruano\n",
    "    - Asistencia y votaciones de congresistas\n",
    "    - Información relacionada a congresistas (identidad, región, actividad legislativa)\n",
    "    - Transparencia y fiscalización gubernamental en general\n",
    "\n",
    "    INSTRUCCIONES:\n",
    "    - Si el contexto histórico muestra que el usuario estuvo hablando de los TEMAS RELEVANTES que se muestran arriba, responde 'YES'.\n",
    "    - Si la última pregunta es sobre un tema totalmente distinto al contexto histórico, responde 'NO'.\n",
    "    - Si no hay contexto histórico, evalúa solo si la última pregunta es sobre los TEMAS RELEVANTES.\n",
    "\n",
    "    Solo responde con 'YES' o 'NO' (sin explicaciones ni comentarios adicionales).\n",
    "\n",
    "    CONTEXTO HISTÓRICO:\n",
    "    {history_context}\n",
    "\n",
    "    ÚLTIMA PREGUNTA:\n",
    "    {last_question}\n",
    "\n",
    "    ¿Se puede responder la última pregunta en el contexto de los TEMAS RELEVANTES?\n",
    "    \"\"\"\n",
    "\n",
    "    classification = llm_classifier.invoke([HumanMessage(content=prompt)])\n",
    "    decision = classification.content.strip().upper()\n",
    "    if decision not in (\"YES\", \"NO\"):\n",
    "        decision = \"NO\"\n",
    "\n",
    "    print(f\"DECISIÓN DEL CLASIFICADOR: {decision}\")\n",
    "\n",
    "    return {\n",
    "        \"raw_messages\": state[\"raw_messages\"],\n",
    "        \"messages\": state[\"messages\"],\n",
    "        \"topic_decision\": decision\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(ChatState)\n",
    "\n",
    "graph.add_node(\"rewriter\", rewrite_node)\n",
    "graph.add_node(\"classifier\", classifier_node)\n",
    "\n",
    "# Definir el flujo: input -> rewriter -> classifier -> end\n",
    "graph.add_edge(START, \"rewriter\")\n",
    "graph.add_edge(\"rewriter\", \"classifier\")\n",
    "graph.add_edge(\"classifier\", END)\n",
    "\n",
    "enhanced_processor = graph.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "=== Test 1: Pregunta sobre contrataciones ===\n",
      "CONTEXTO HISTÓRICO:\n",
      "\n",
      "\n",
      "ÚLTIMA PREGUNTA:\n",
      "¿Qué empresas tienen contratos con el Estado peruano por más de 1,000,000 de soles según los registros de transparencia pública?\n",
      "\n",
      "\n",
      "DECISIÓN DEL CLASIFICADOR: YES\n",
      "Pregunta original: Que empresas tienen contratos por más de 1000000 de soles\n",
      "Pregunta reescrita: ¿Qué empresas tienen contratos con el Estado peruano por más de 1,000,000 de soles según los registros de transparencia pública?\n",
      "Clasificación: YES\n",
      "\n",
      "****************************************************************************************************\n",
      "=== Test 2: Pregunta general ===\n",
      "CONTEXTO HISTÓRICO:\n",
      "Q: ¿Qué empresas tienen contratos con el Estado peruano por más de 1,000,000 de soles según los registros de transparencia pública?\n",
      "A: [Pendiente de responder...]\n",
      "\n",
      "ÚLTIMA PREGUNTA:\n",
      "Quien ganó la Champions League\n",
      "\n",
      "\n",
      "DECISIÓN DEL CLASIFICADOR: NO\n",
      "Pregunta original: Quien ganó la Champions League\n",
      "Pregunta reescrita: Quien ganó la Champions League\n",
      "Clasificación: NO\n",
      "\n",
      "****************************************************************************************************\n",
      "=== Test 3: Pregunta sobre asistencias ===\n",
      "CONTEXTO HISTÓRICO:\n",
      "Q: ¿Qué empresas tienen contratos con el Estado peruano por más de 1,000,000 de soles según los registros de transparencia pública?\n",
      "A: [Pendiente de responder...]\n",
      "\n",
      "Q: Quien ganó la Champions League\n",
      "A: [Pendiente de responder...]\n",
      "\n",
      "ÚLTIMA PREGUNTA:\n",
      "¿Cuáles fueron las asistencias de los congresistas en octubre de 2022?\n",
      "\n",
      "\n",
      "DECISIÓN DEL CLASIFICADOR: YES\n",
      "Pregunta original: dame las asistencias del 2022 octubre\n",
      "Pregunta reescrita: ¿Cuáles fueron las asistencias de los congresistas en octubre de 2022?\n",
      "Clasificación: YES\n",
      "\n",
      "****************************************************************************************************\n",
      "=== Test 4:  sobre que mas puedes hacer ===\n",
      "CONTEXTO HISTÓRICO:\n",
      "Q: ¿Qué empresas tienen contratos con el Estado peruano por más de 1,000,000 de soles según los registros de transparencia pública?\n",
      "A: [Pendiente de responder...]\n",
      "\n",
      "Q: Quien ganó la Champions League\n",
      "A: [Pendiente de responder...]\n",
      "\n",
      "Q: ¿Cuáles fueron las asistencias de los congresistas en octubre de 2022?\n",
      "A: [Pendiente de responder...]\n",
      "\n",
      "ÚLTIMA PREGUNTA:\n",
      "que mas puedes hacer\n",
      "\n",
      "\n",
      "DECISIÓN DEL CLASIFICADOR: NO\n",
      "Pregunta original: que mas puedes hacer\n",
      "Pregunta reescrita: que mas puedes hacer\n",
      "Clasificación: NO\n",
      "\n",
      "****************************************************************************************************\n",
      "=== Test 5: Pregunta sobre los contratos de la empresa constructora alfa ===\n",
      "CONTEXTO HISTÓRICO:\n",
      "Q: ¿Qué empresas tienen contratos con el Estado peruano por más de 1,000,000 de soles según los registros de transparencia pública?\n",
      "A: [Pendiente de responder...]\n",
      "\n",
      "Q: Quien ganó la Champions League\n",
      "A: [Pendiente de responder...]\n",
      "\n",
      "Q: ¿Cuáles fueron las asistencias de los congresistas en octubre de 2022?\n",
      "A: [Pendiente de responder...]\n",
      "\n",
      "Q: que mas puedes hacer\n",
      "A: [Pendiente de responder...]\n",
      "\n",
      "ÚLTIMA PREGUNTA:\n",
      "¿Cuáles son los detalles de los contratos de la empresa 'CONSTRUCTORA ALFA'?\n",
      "\n",
      "\n",
      "DECISIÓN DEL CLASIFICADOR: YES\n",
      "Pregunta original: detalles de los contratos de constructora alfa\n",
      "Pregunta reescrita: ¿Cuáles son los detalles de los contratos de la empresa 'CONSTRUCTORA ALFA'?\n",
      "Clasificación: YES\n",
      "\n",
      "****************************************************************************************************\n",
      "=== Test 5:  sobre que mas sabes de la empresa ===\n",
      "CONTEXTO HISTÓRICO:\n",
      "Q: Quien ganó la Champions League\n",
      "A: [Pendiente de responder...]\n",
      "\n",
      "Q: ¿Cuáles fueron las asistencias de los congresistas en octubre de 2022?\n",
      "A: [Pendiente de responder...]\n",
      "\n",
      "Q: que mas puedes hacer\n",
      "A: [Pendiente de responder...]\n",
      "\n",
      "Q: ¿Cuáles son los detalles de los contratos de la empresa 'CONSTRUCTORA ALFA'?\n",
      "A: [Pendiente de responder...]\n",
      "\n",
      "ÚLTIMA PREGUNTA:\n",
      "que mas sabes de la empresa\n",
      "\n",
      "\n",
      "DECISIÓN DEL CLASIFICADOR: YES\n",
      "Pregunta original: que mas sabes de la empresa\n",
      "Pregunta reescrita: que mas sabes de la empresa\n",
      "Clasificación: YES\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "session_id = \"abc123\"\n",
    "\n",
    "# Test 1: Pregunta sobre transparencia gubernamental (debe ir a main)\n",
    "print(\"*\"*100)\n",
    "print(\"=== Test 1: Pregunta sobre contrataciones ===\")\n",
    "state = enhanced_processor.invoke(\n",
    "    {\n",
    "        \"raw_messages\": [HumanMessage(content=\"Que empresas tienen contratos por más de 1000000 de soles\")],\n",
    "        \"topic_decision\": \"\"\n",
    "    },\n",
    "    config={\"thread_id\": session_id}\n",
    ")\n",
    "print(f\"Pregunta original: {state['raw_messages'][-1].content}\")\n",
    "print(f\"Pregunta reescrita: {state['messages'][-1].content}\")\n",
    "print(f\"Clasificación: {state['topic_decision']}\")\n",
    "print()\n",
    "\n",
    "# Test 2: Pregunta general (debe ir a fallback)\n",
    "print(\"*\"*100)\n",
    "print(\"=== Test 2: Pregunta general ===\")\n",
    "state = enhanced_processor.invoke(\n",
    "    {\n",
    "        \"raw_messages\": [HumanMessage(content=\"Quien ganó la Champions League\")],\n",
    "        \"topic_decision\": \"\"\n",
    "    },\n",
    "    config={\"thread_id\": session_id}  \n",
    ")\n",
    "print(f\"Pregunta original: {state['raw_messages'][-1].content}\")\n",
    "print(f\"Pregunta reescrita: {state['messages'][-1].content}\")\n",
    "print(f\"Clasificación: {state['topic_decision']}\")\n",
    "print()\n",
    "\n",
    "# Test 3: Pregunta sobre asistencias (debe ir a main)\n",
    "print(\"*\"*100)\n",
    "print(\"=== Test 3: Pregunta sobre asistencias ===\")\n",
    "state = enhanced_processor.invoke(\n",
    "    {\n",
    "        \"raw_messages\": [HumanMessage(content=\"dame las asistencias del 2022 octubre\")],\n",
    "        \"topic_decision\": \"\"\n",
    "    },\n",
    "    config={\"thread_id\": session_id}  \n",
    ")\n",
    "print(f\"Pregunta original: {state['raw_messages'][-1].content}\")\n",
    "print(f\"Pregunta reescrita: {state['messages'][-1].content}\")\n",
    "print(f\"Clasificación: {state['topic_decision']}\")\n",
    "print()\n",
    "\n",
    "# Test 4: Pregunta sobre que mas puedes hacer\n",
    "print(\"*\"*100)\n",
    "print(\"=== Test 4:  sobre que mas puedes hacer ===\")\n",
    "state = enhanced_processor.invoke(\n",
    "    {\n",
    "        \"raw_messages\": [HumanMessage(content=\"que mas puedes hacer\")],\n",
    "        \"topic_decision\": \"\"\n",
    "    },\n",
    "    config={\"thread_id\": session_id}  \n",
    ")\n",
    "print(f\"Pregunta original: {state['raw_messages'][-1].content}\")\n",
    "print(f\"Pregunta reescrita: {state['messages'][-1].content}\")\n",
    "print(f\"Clasificación: {state['topic_decision']}\")\n",
    "print()\n",
    "\n",
    "# Test 5: Pregunta sobre los contratos de la empresa constructora alfa\n",
    "print(\"*\"*100)\n",
    "print(\"=== Test 5: Pregunta sobre los contratos de la empresa constructora alfa ===\")\n",
    "state = enhanced_processor.invoke(\n",
    "    {\n",
    "        \"raw_messages\": [HumanMessage(content=\"detalles de los contratos de constructora alfa\")],\n",
    "        \"topic_decision\": \"\"\n",
    "    },\n",
    "    config={\"thread_id\": session_id}  \n",
    ")\n",
    "print(f\"Pregunta original: {state['raw_messages'][-1].content}\")\n",
    "print(f\"Pregunta reescrita: {state['messages'][-1].content}\")\n",
    "print(f\"Clasificación: {state['topic_decision']}\")\n",
    "print()\n",
    "\n",
    "# Test 5: Pregunta sobre que mas puedes hacer\n",
    "print(\"*\"*100)\n",
    "print(\"=== Test 5:  sobre que mas sabes de la empresa ===\")\n",
    "state = enhanced_processor.invoke(\n",
    "    {\n",
    "        \"raw_messages\": [HumanMessage(content=\"que mas sabes de la empresa\")],\n",
    "        \"topic_decision\": \"\"\n",
    "    },\n",
    "    config={\"thread_id\": session_id}  \n",
    ")\n",
    "print(f\"Pregunta original: {state['raw_messages'][-1].content}\")\n",
    "print(f\"Pregunta reescrita: {state['messages'][-1].content}\")\n",
    "print(f\"Clasificación: {state['topic_decision']}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(enhanced_processor.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_budget",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
